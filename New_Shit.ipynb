{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# from auto_ml import Predictor\n",
    "\n",
    "def eval_tree_based_model_max_depth(clf, max_depth, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This function evaluates the given classifier (either a decision tree or random forest) at all of the \n",
    "    maximum tree depth parameters in the vector max_depth, using the given training and testing\n",
    "    data. It returns two vector, with the training and testing classification errors.\n",
    "    \n",
    "    Inputs:\n",
    "        clf: either a decision tree or random forest classifier object\n",
    "        max_depth: a (T, ) vector of all the max_depth stopping condition parameters \n",
    "                            to test, where T is the number of parameters to test\n",
    "        X_train: (N, D) matrix of training samples.\n",
    "        y_train: (N, ) vector of training labels.\n",
    "        X_test: (N, D) matrix of test samples\n",
    "        y_test: (N, ) vector of test labels\n",
    "    Output:\n",
    "        train_err: (T, ) vector of classification errors on the training data\n",
    "        test_err: (T, ) vector of classification errors on the test data\n",
    "    \"\"\"\n",
    "    training_errors = []\n",
    "    test_errors = []\n",
    "    # evaluates the tree classifier for the desired number of max_tree_depth values values \n",
    "    for i in range(len(max_depth)):\n",
    "        print(max_depth[i])\n",
    "        clf.set_params(min_samples_leaf = max_depth[i])\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_train_predict = clf.predict_proba(X_train)[:, 1]\n",
    "        y_test_predict = clf.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        training_errors.append(roc_auc_score(y_train, y_train_predict))\n",
    "        test_errors.append(roc_auc_score( y_test, y_test_predict))\n",
    "    return np.array(training_errors), np.array(test_errors)\n",
    "\n",
    "def classification_err(y, real_y):\n",
    "    \"\"\"\n",
    "    This function returns the classification error between two equally-sized vectors of \n",
    "    labels; this is the fraction of samples for which the labels differ.\n",
    "    \n",
    "    Inputs:\n",
    "        y: (N, ) shaped array of predicted labels\n",
    "        real_y: (N, ) shaped array of true labels\n",
    "    Output:\n",
    "        Scalar classification error\n",
    "    \"\"\"\n",
    "    return sum(y != real_y)/len(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(open(\"train_2008.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "test_data = np.loadtxt(open(\"test_2008.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "\n",
    "X = data[:, 3:382]\n",
    "y = data[:, 382]\n",
    "print(y)\n",
    "X_test = test_data[:, 3:382]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42  35   8 333   3 194 187 328 192  33 317 325  37   9  51 225 229 228\n",
      "  24 331  25 327  26 332 226 244 322 255 185 319 321 230  31  46 231 318\n",
      "  12 221  43  60 315 336 190  11  27 316  13  58  48  32   4 358  55  53\n",
      " 224  14  28  49  61  93 330  70  54  23  44  91 355 152  59 171  17  50\n",
      "  15  56  39 314 227 180 182  79   0 348  82 223 349 172 352 359 183  69\n",
      " 324 156  38  66 163 313  29  73 356 241 175  68  74 329   5 170 208  47\n",
      " 159 205 218 347  18  16 169 283 176 168  87 338 177 271 357 158   7  40\n",
      " 220 246  97  89 204 155 138 222 101  19  64 265 346 270  34 200 219 344\n",
      " 326 113   1  88 264  83 351 102 343 266 237 312  96   6 306 147 311 258\n",
      " 153 295  99 320 162 261 154 285 256 302 202 310 164  30  85 267 130 263\n",
      "  95 291 350 293 345  71  36 269 197  98 303 100 260 232 179 305 323 294\n",
      "  77 214 259 308 160 296 249 215 284 304 309 128 198 207 199  86 257 150\n",
      " 268 287 286 307 300 353 201 354 216 301 233 178  90 289  45 288 290 114\n",
      " 282 123 277 292 217  62 161  20   2 240 129 262 278 115 148 146 125 279\n",
      " 281  84  81 141 127 126 166 143 203  78  80 280 276 157  94  92 131 142\n",
      " 103 213  67  57 116 239 339 149  75 132 248 236 363 247  65 104 361 251\n",
      " 117 297 133 250 136  63 134  76 173 365 362 135 252 151 334 299 165 337\n",
      " 275 340 186 298 364 145 110 209 188 191 243 242 245  21  22 238 112 111\n",
      " 253 109 108 107 234  10 360 106 254 272 273 105 274 235 139 118 335 137\n",
      " 144  72 167 124 122 174 181  52 184 121 189 212 120  41 119 341 193 342\n",
      " 195 140 206 210 211 196]\n",
      "366\n"
     ]
    }
   ],
   "source": [
    "i_love_indices = np.loadtxt(open(\"i_love_indices.txt\", \"r\"))\n",
    "i_love_indices = i_love_indices.astype(int)\n",
    "print(i_love_indices)\n",
    "print(len(i_love_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43  36   8   3 338 196 333 191  34 198 322 330  52 337 230  10 234 336\n",
      "  25 233  26  38 332 231  27 324 189 260  47 249 327 321  61 235 320 236\n",
      "  32 326  44  13  28 319 341 226 194 323  12  14 335   4  59  49 363  56\n",
      "  33  55  29  50  15  62  45  94  24 229  54  71 186 354  92  16 156  18\n",
      " 175  40 232  60 360  83   0  57  51  80 353 228 187 176 184 357 364 160\n",
      "  39  30  69  70 167 334  48 179 329 213 361 276 352  67 163 288   5  17\n",
      "  65  74 343 181 318 210 246  88  19 172 173  75 174 223 180 162 356   7\n",
      " 270 251  41 351  90  98 102 225  35 224 159 269  20 362 114 331 158 134\n",
      " 261  97 204 272 142 209  86 349 157 151   1 242 328 227 275 296 316 355\n",
      " 166 271 315  89 100 298  84 350 274 206 307 103 263 262 348 311  99   6\n",
      " 308 265 317  31 203 268 183 266 101 168 325  72  37  78 313 273 201 300\n",
      " 154 219 237 264 202 290 254  96 221 310 309 306 314 305 164 289 220 312\n",
      " 205 132 182 299  87 358 292 212 238 301 291 293  91 282  46 295 165 359\n",
      " 294 115 283 297 286 222 245 127 281  63 152 129 267 133 147 208  82  93\n",
      " 284 285  21 116 131 146 150   2  81 287 170  79 145 218  95  58 153  85\n",
      " 136 130 253  68 344 161  77 244 135 367 252 185 117 366 155 257 342 140\n",
      " 105 256  76 369 104 241  66 304 365 192 368 303 339 188 190 370 138 177\n",
      " 149 109 110 195 302 345 340 106 215 197 169 214  23 277 118 255  22 113\n",
      " 250 258 259 126 112 278 279 280 247 111  11   9 346 347 108 107 248 217\n",
      " 243 123  64 137 139 125 141 143 144 148 124  53 171 178 122 119 121  73\n",
      " 120  42 199 200 207 211 216 128 239 240 193]\n",
      "371\n",
      "[ 43  36   8 333 191  34 198 322 330  52 337 230  10 234 336  25 233  26\n",
      "  38 332 231  27 324 189 260  47 249 327 321  61 235 320 236  32 326  44\n",
      "  13  28 319 341 226 194 323  12  14 335   4  59  49 363  56  33  55  29\n",
      "  50  15  62  45  94  24 229  54  71 186 354  92  16 156  18 175  40 232\n",
      "  60 360  83   0  57  51  80 353 228 187 176 184 357 364 160  39  30  69\n",
      "  70 167 334  48 179 329 213 361 276 352  67 163 288   5  17  65  74 343\n",
      " 181 318 210 246  88  19 172 173  75 174 223 180 162 356   7 270 251  41\n",
      " 351  90  98 102 225  35 224 159 269  20 362 114 331 158 134 261  97 204\n",
      " 272 142 209  86 349 157 151   1 242 328 227 275 296 316 355 166 271 315\n",
      "  89 100 298  84 350 274 206 307 103 263 262 348 311  99   6 308 265 317\n",
      "  31 203 268 183 266 101 168 325  72  37  78 313 273 201 300 154 219 237\n",
      " 264 202 290 254  96 221 310 309 306 314 305 164 289 220 312 205 132 182\n",
      " 299  87 358 292 212 238 301 291 293  91 282  46 295 165 359 294 115 283\n",
      " 297 286 222 245 127 281  63 152 129 267 133 147 208  82  93 284 285  21\n",
      " 116 131 146 150   2  81 287 170  79 145 218  95  58 153  85 136 130 253\n",
      "  68 344 161  77 244 135 367 252 185 117 366 155 257 342 140 105 256  76\n",
      " 369 104 241  66 304 365 192 368 303 339 188 190 370 138 177 149 109 110\n",
      " 195 302 345 340 106 215 197 169 214  23 277 118 255  22 113 250 258 259\n",
      " 126 112 278 279 280 247 111  11   9 346 347 108 107 248 217 243 123  64\n",
      " 137 139 125 141 143 144 148 124  53 171 178 122 119 121  73 120  42 199\n",
      " 200 207 211 216 128 239 240 193]\n"
     ]
    }
   ],
   "source": [
    "sum(X[:, 10]<0)\n",
    "print(i_love_indices)\n",
    "print(len(i_love_indices))\n",
    "to_delete = [1,2,3,4,5]\n",
    "print(np.delete(i_love_indices, to_delete[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64667, 379)\n",
      "(16000, 379)\n",
      "[9, 11, 126, 127, 128, 132, 133, 134]\n",
      "[9, 10, 11, 124, 125, 126, 127, 128, 131, 132, 133, 134, 215]\n",
      "(64667, 371)\n",
      "(16000, 371)\n",
      "(64667, 371)\n",
      "(16000, 366)\n"
     ]
    }
   ],
   "source": [
    "X[X < 0] = -1\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "bad_indices = []\n",
    "real_bad_indices = []\n",
    "for i in range(np.shape(X)[1]):\n",
    "    num_less = X[:,i] < 0\n",
    "    #bad_indices.append(float(sum(num_less))/float(len(num_less)))\n",
    "    if sum(num_less)/len(num_less) == 1:\n",
    "        real_bad_indices.append(i)\n",
    "        \n",
    "print(real_bad_indices)\n",
    "# print(bad_indices[45])\n",
    "\n",
    "real_bad_indices_2 = []\n",
    "for i in range(np.shape(X_test)[1]):\n",
    "    num_less = X_test[:,i] < 0\n",
    "    if sum(num_less)/len(num_less) == 1:\n",
    "        real_bad_indices_2.append(i)\n",
    "            \n",
    "print(real_bad_indices_2)  \n",
    "X = np.delete(X, real_bad_indices, axis = 1)\n",
    "X_test = np.delete(X_test, real_bad_indices,axis = 1)\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "imp = Imputer(missing_values=-1, strategy='mean')\n",
    "X = imp.fit_transform(X)\n",
    "imp = Imputer(missing_values=-1, strategy='mean')\n",
    "X_test = imp.fit_transform(X_test)\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "real_bad_indices_2 = np.array([9, 10, 11, 124, 125, 126, 127, 128, 131, 132, 133, 134, 215])\n",
    "print(len(real_bad_indices_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "(64667, 116)\n",
      "[0.7910013374006912]\n",
      "[0.8165327645136072]\n",
      "[0.50039632 0.49715136 0.50114489 ... 0.49326155 0.49848864 0.49825511]\n",
      "160\n",
      "(64667, 116)\n",
      "[0.7910013374006912, 0.7913798358275573]\n",
      "[0.8165327645136072, 0.8179251412299803]\n",
      "[0.50038904 0.49732561 0.5011789  ... 0.4937029  0.49857061 0.49829022]\n",
      "170\n",
      "(64667, 116)\n",
      "[0.7910013374006912, 0.7913798358275573, 0.790945462632921]\n",
      "[0.8165327645136072, 0.8179251412299803, 0.8189735133672766]\n",
      "[0.50037386 0.49750768 0.50120378 ... 0.49395323 0.49870835 0.49839152]\n",
      "180\n",
      "(64667, 116)\n",
      "[0.7910013374006912, 0.7913798358275573, 0.790945462632921, 0.7913151798462836]\n",
      "[0.8165327645136072, 0.8179251412299803, 0.8189735133672766, 0.8204579934055635]\n",
      "[0.50032519 0.49769566 0.50109152 ... 0.49424346 0.49869532 0.4984229 ]\n",
      "190\n",
      "(64667, 116)\n",
      "[0.7910013374006912, 0.7913798358275573, 0.790945462632921, 0.7913151798462836, 0.7909613063170706]\n",
      "[0.8165327645136072, 0.8179251412299803, 0.8189735133672766, 0.8204579934055635, 0.8215260711868219]\n",
      "[0.5004332  0.49776678 0.50114232 ... 0.49444093 0.49886282 0.49849926]\n",
      "200\n",
      "(64667, 116)\n",
      "[0.7910013374006912, 0.7913798358275573, 0.790945462632921, 0.7913151798462836, 0.7909613063170706, 0.7909374001664305]\n",
      "[0.8165327645136072, 0.8179251412299803, 0.8189735133672766, 0.8204579934055635, 0.8215260711868219, 0.8227959478285066]\n",
      "[0.50036504 0.497896   0.50102344 ... 0.49463413 0.49880578 0.49858008]\n",
      "210\n",
      "(64667, 116)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ed2094195d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# print('SVM done')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#     print(clf.classes_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 335\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    170\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'multiclass'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# kf = KFold(n_splits = 5, shuffle = True) \n",
    "\n",
    "# all_predictions = np.zeros(5)\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_val = X[train_index], X[test_index]\n",
    "#     y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "#     #fprint(np.shape(y_test))\n",
    "#     scaler = StandardScaler()\n",
    "#     # Fit on training set only.\n",
    "#     scaler.fit(X_train)\n",
    "#     # Apply transform to both the training set and the test set.\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_val = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "training_errors = []\n",
    "test_errors = []\n",
    "max_depth = np.arange(150, 220, 10)\n",
    "for est in max_depth:\n",
    "#    \n",
    "#     max_depth = np.arange(15,200,15)\n",
    "#     for est in max_depth:\n",
    "        #print(slices, est)\n",
    "\n",
    "    X = data[:, 3:382]\n",
    "    y = data[:, 382]\n",
    "    print(est)\n",
    "    X[X < 0] = -1\n",
    "    X = np.delete(X, real_bad_indices_2, axis = 1)\n",
    "    imp = Imputer(missing_values=-1, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "    X = np.delete(X, i_love_indices[len(i_love_indices) - 250:], axis=1)\n",
    "\n",
    "    print(X.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(X)\n",
    "    # X_train = scaler.transform(X_train)\n",
    "    # X_test = scaler.transform(X_test)\n",
    "\n",
    "    # pca = PCA(n_components = 75)\n",
    "    # pca.fit(X_train)\n",
    "    # X_train = pca.transform(X_train)\n",
    "    # X_test = pca.transform(X_test)\n",
    "    #      #X_val = pca.transform(X_val)\n",
    "\n",
    "    # print('PCA done')\n",
    "    clf1 = RandomForestClassifier(max_depth = 2, min_samples_leaf = 20, n_estimators = 190)\n",
    "    # clf = svm.SVC(probability = True, verbose=True)\n",
    "\n",
    "    clf = AdaBoostClassifier(base_estimator = clf1, n_estimators = est)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print('SVM done')\n",
    "    #     print(clf.classes_)\n",
    "    #clf.fit(X, y)\n",
    "\n",
    "    #     predictions = clf.predict_proba(X_val)[:, 1]\n",
    "    #     print(sum(np.floor(2.0*predictions) != np.array(y_val))/len(predictions))\n",
    "    #     print(roc_auc_score(y_val, predictions))\n",
    "    #     importances = clf.feature_importances_\n",
    "    #     indices = np.argsort(importances)[::-1]\n",
    "    #     #Print the feature ranking\n",
    "    #     print(\"Feature ranking:\")\n",
    "    #     for f in range(X.shape[1]):\n",
    "    #         print(\"%d. feature %d (%f)\" % (f, indices[f], importances[indices[f]]))\n",
    "    #         #print(X_train[:, indices[f]])\n",
    "\n",
    "\n",
    "    #print(1) \n",
    "    #max_depth = np.arange(10, 200, 20)\n",
    "    #train_err, test_err = eval_tree_based_model_max_depth(clf, max_depth, X_train, y_train, X_val, y_val)\n",
    "\n",
    "\n",
    "    y_train_predict = clf.predict_proba(X_train)[:, 1]\n",
    "    y_test_predict = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    training_errors.append(roc_auc_score(y_train, y_train_predict))\n",
    "    test_errors.append(roc_auc_score(y_test, y_test_predict))\n",
    "    print(test_errors)\n",
    "    print(training_errors)\n",
    "    \n",
    "    results = clf.predict_proba(X_test)\n",
    "    print(results[:, 1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_depth, test_errors, label='Testing error')\n",
    "plt.plot(max_depth, training_errors, label='Training error')\n",
    "plt.xlabel('Maximum Tree Depth')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Decision Tree with Gini Impurity and Maximum Tree Depth')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.show()\n",
    "\n",
    "print('Test error minimized at max_depth =', np.max(test_errors), max_depth[np.argmax(test_errors)])\n",
    "print(test_errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errors = np.array([.788315, .790069, .790413, .790473, .790514,.791090])\n",
    "training_eroros = np.array([.818969, .820502, .821072, .821033, .821689, .820971])\n",
    "max_depth = np.array([10,20,30,40,50,60])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_depth, test_errors, label='Testing error')\n",
    "plt.plot(max_depth, training_errors, label='Training error')\n",
    "plt.xlabel('Maximum Tree Depth')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Decision Tree with Gini Impurity and Maximum Tree Depth')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error minimized at max_depth = 0.7811935031645026 285\n",
      "[0.7790570432941638, 0.7785818265192835, 0.7808646139064485, 0.7798827898621545, 0.7797951339764745, 0.7797162280544273, 0.7807279894742938, 0.7801513199960762, 0.7807501143823371, 0.7794381510851845, 0.7800824140324667, 0.7790893869097356, 0.7805945056540857, 0.7799728519878338, 0.7802944912760206, 0.7811935031645026]\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(max_depth, test_errors[8:], label='Testing error')\n",
    "plt.plot(max_depth, training_errors[8:], label='Training error')\n",
    "plt.xlabel('Maximum Tree Depth')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Decision Tree with Gini Impurity and Maximum Tree Depth')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.show()\n",
    "print('Test error minimized at max_depth =', np.max(test_errors[8:]), max_depth[np.argmax(test_errors[8:])])\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACTUAL MODEL CODE\n",
    "\n",
    "data = np.loadtxt(open(\"train_2008.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "test_data = np.loadtxt(open(\"test_2008.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "\n",
    "X = data[:, 3:382]\n",
    "y = data[:, 382]\n",
    "\n",
    "X_test = test_data[:, 3:382]\n",
    "\n",
    "X[X < 0] = -1\n",
    "X = np.delete(X, real_bad_indices_2, axis = 1)\n",
    "imp = Imputer(missing_values=-1, strategy='mean')\n",
    "X = imp.fit_transform(X)\n",
    "\n",
    "X = np.delete(X, i_love_indices[len(i_love_indices) - 250:], axis=1)\n",
    "\n",
    "\n",
    "#X_test[X_test < 0] = -1\n",
    "X_test = np.delete(X_test, real_bad_indices_2,axis = 1)\n",
    "imp = Imputer(missing_values=-1, strategy='mean')\n",
    "X_test = imp.fit_transform(X_test)\n",
    "\n",
    "X_test = np.delete(X_test, i_love_indices[len(i_love_indices) - 250:], axis=1)\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# pca = PCA(n_components = 75)\n",
    "# pca.fit(X)\n",
    "# X = pca.transform(X)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "# #print(X.shape)\n",
    "\n",
    "clf1 = RandomForestClassifier(max_depth = 2, min_samples_leaf = 20, n_estimators = 190)\n",
    "clf = AdaBoostClassifier(base_estimator = clf1, n_estimators = 160)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# importances = clf.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# #Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f, indices[f], importances[indices[f]]))\n",
    "#     #print(X_train[:, indices[f]])\n",
    "    \n",
    "# i_love_indices = indices\n",
    "\n",
    "results = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.DataFrame(data = X)\n",
    "# df_test = pd.DataFrame(data = X_test)\n",
    "\n",
    "# ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)\n",
    "# ml_predictor.train(df_train)\n",
    "# ml_predictor.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_results = results[:, 1]\n",
    "#new_results[new_results < 0.03] = 0\n",
    "#new_results[new_results > 0.67] = 1\n",
    "with open('output_1.csv', 'w') as output:\n",
    "    output.write('id,target\\n')\n",
    "    for i in range(len(test_data)):\n",
    "        output.write(str(int(test_data[i][0])) + ',' + str(new_results[i]) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8198093  0.80898397 0.79962917 0.79021625 0.78625062 0.78174169\n",
      " 0.77853367 0.77287553 0.77251965 0.76782463 0.76634991 0.76543805\n",
      " 0.76533352 0.76396577 0.76154461 0.75544078 0.75501377 0.75472866\n",
      " 0.7546399  0.75458857 0.75358048 0.75243728 0.75224463 0.7498976\n",
      " 0.74829219 0.74430351 0.74257807 0.74173416 0.74158917 0.74113962\n",
      " 0.73908588 0.73775042 0.73564811 0.73533103 0.73526861 0.73502455\n",
      " 0.73359814 0.73351175 0.73261683 0.73128456 0.72906647 0.72233281\n",
      " 0.72222513 0.7200193  0.7192253  0.71918656 0.71897341 0.71838145\n",
      " 0.71754991 0.71695955 0.71683241 0.71653549 0.71561504 0.71463297\n",
      " 0.7145744  0.71417955 0.71383217 0.71223372 0.71113641 0.71004102\n",
      " 0.70977054 0.70806521 0.7076079  0.70668292 0.70667916 0.70656725\n",
      " 0.70564052 0.70539752 0.70490761 0.70478262 0.70475867 0.70447995\n",
      " 0.70446921 0.70346516 0.70319091 0.70317852 0.70299224 0.70291811\n",
      " 0.70213975 0.70203857 0.70186658 0.70141378 0.70111054 0.7006842\n",
      " 0.70051245 0.70028475 0.69987121 0.69960211 0.69884543 0.69878389\n",
      " 0.69841817 0.69743702 0.69682552 0.69671847 0.69669214 0.69650423\n",
      " 0.69620605 0.69605726 0.69468834 0.69415874 0.69375805 0.69342542\n",
      " 0.69332111 0.692934   0.69288878 0.69256172 0.6923803  0.69212319\n",
      " 0.69183763 0.69156186 0.69147395 0.69111863 0.69108108 0.69106604\n",
      " 0.69052419 0.69043799 0.69036867 0.6903036  0.69025606 0.6902116\n",
      " 0.69019645 0.68955113 0.68919276 0.68913481 0.68903362 0.68873365\n",
      " 0.68856146 0.6878742  0.68771148 0.68761283 0.68708706 0.68706852\n",
      " 0.68701615 0.68671901 0.68604571 0.68539655 0.68446284 0.68441443\n",
      " 0.68378376 0.6835921  0.68336966 0.6832783  0.68311927 0.68306499\n",
      " 0.68267288 0.68173496 0.681688   0.6815027  0.68137141 0.68123768\n",
      " 0.6811592  0.68043336 0.68029614 0.67949848 0.67941518 0.67929582\n",
      " 0.67923569 0.67908377 0.67890448 0.67882728 0.67841723 0.67829007\n",
      " 0.67817308 0.67807106 0.67800632 0.67796617 0.67779293 0.6775005\n",
      " 0.67730213 0.67715647 0.67704394 0.6766525  0.67664756 0.67644237\n",
      " 0.67557175 0.67521053 0.67478057 0.67472673 0.67467059 0.67420578]\n"
     ]
    }
   ],
   "source": [
    "test = np.copy(results[:, 1])\n",
    "\n",
    "test.sort()\n",
    "print(test[::-1][:180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42  35   8 333   3 194 187 328 192  33 317 325  37   9  51 225 229 228\n",
      "  24 331  25 327  26 332 226 244 322 255 185 319 321 230  31  46 231 318\n",
      "  12 221  43  60 315 336 190  11  27 316  13  58  48  32   4 358  55  53\n",
      " 224  14  28  49  61  93 330  70  54  23  44  91 355 152  59 171  17  50\n",
      "  15  56  39 314 227 180 182  79   0 348  82 223 349 172 352 359 183  69\n",
      " 324 156  38  66 163 313  29  73 356 241 175  68  74 329   5 170 208  47\n",
      " 159 205 218 347  18  16 169 283 176 168  87 338 177 271 357 158   7  40\n",
      " 220 246  97  89 204 155 138 222 101  19  64 265 346 270  34 200 219 344\n",
      " 326 113   1  88 264  83 351 102 343 266 237 312  96   6 306 147 311 258\n",
      " 153 295  99 320 162 261 154 285 256 302 202 310 164  30  85 267 130 263\n",
      "  95 291 350 293 345  71  36 269 197  98 303 100 260 232 179 305 323 294\n",
      "  77 214 259 308 160 296 249 215 284 304 309 128 198 207 199  86 257 150\n",
      " 268 287 286 307 300 353 201 354 216 301 233 178  90 289  45 288 290 114\n",
      " 282 123 277 292 217  62 161  20   2 240 129 262 278 115 148 146 125 279\n",
      " 281  84  81 141 127 126 166 143 203  78  80 280 276 157  94  92 131 142\n",
      " 103 213  67  57 116 239 339 149  75 132 248 236 363 247  65 104 361 251\n",
      " 117 297 133 250 136  63 134  76 173 365 362 135 252 151 334 299 165 337\n",
      " 275 340 186 298 364 145 110 209 188 191 243 242 245  21  22 238 112 111\n",
      " 253 109 108 107 234  10 360 106 254 272 273 105 274 235 139 118 335 137\n",
      " 144  72 167 124 122 174 181  52 184 121 189 212 120  41 119 341 193 342\n",
      " 195 140 206 210 211 196]\n"
     ]
    }
   ],
   "source": [
    "print(i_love_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
